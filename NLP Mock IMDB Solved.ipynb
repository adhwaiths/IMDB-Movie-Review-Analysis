{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5def68",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Kickoffs - IMDB Movie Review Analysis üçø\n",
    "\n",
    "*Given a dataset consisting of reviews posted on IMDB for movies and series. Though the dataset may seem as a CSV file, it's record comes with a little toss of HTML code with it. We need to analyze this data using NLP techniques and get some useful insights out of it.*\n",
    "\n",
    "##### After completing this challenge, you will be able to:\n",
    "+ Understand the concepts of Data preprocessing.\n",
    "+ NLP Concepts.\n",
    "+ Machine learning models using SKlearn and NLTK.\n",
    "+ Intense data pre-processing methods\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e17d94a-1dd9-4d96-897c-8dc24575517f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file .ans already exists.\n",
      "Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Manage App Execution Aliases.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "!mkdir .ans\n",
    "!python3 -m nltk.downloader all\n",
    "from test_imdb import test_imdb\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422e86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"test_imdb-0.1-py3-none-any.whl\") as f:\n",
    "    f.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0050c852",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Task 1 : Data Loading and Exploration,Data Preprocessing\n",
    "+ Load the IMDB reviews dataset `imdb.csv` to a pandas dataframe named `data`.\n",
    "- Utilize Pandas functions (`info()`, `head()`, `describe()`) to explore the structure, columns, and initial samples of the `data` dataset.\n",
    "- Analyze the distribution and characteristics of text features in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd3c33b-1686-41b0-9d7f-2452e0b1b60a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a54ec86-82fb-42a7-904d-96c1380203f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7460b57d-557c-431d-a9ee-0e934da6184e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     2000 non-null   object\n",
      " 1   sentiment  2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288869c9-f0b0-498e-9c1d-af773abe7921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                                2000      2000\n",
       "unique                                               2000         2\n",
       "top     One of the other reviewers has mentioned that ...  positive\n",
       "freq                                                    1      1005"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18204d3",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Data Preprocessing\n",
    "+ Complete the following function `clean_text` to remove HTML tags, punctuations and stopwords for the `review` column.\n",
    "+ Using regex - remove the HTML tags, remove all the punctuations in each record.\n",
    "+ Tokenize the text data and remove all the stopwords in it. Join the tokens back into a sentence once the removal process is complete and return the cleaned text.\n",
    "+ Apply the `clean_text` function on the `reviews` column of `data` dataset and store it in a new column called `clean_review`.\n",
    "\n",
    "***Sample dataset after cleaning***:\n",
    "\n",
    "review | sentiment | clean_review\n",
    "------ | ---------- | -----------\n",
    "A wonderful little production. \\<br />\\<br />The filming technique is very unassuming- | positive | wonderful little production filming technique unassuming\n",
    "Probably my all-time favorite movie | positive | Probably alltime favorite movie\n",
    "\n",
    "**Note:** Do not modify the function name.\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f9ab17-a1a6-4efe-b47d-4c0c091bbec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Do not modify function name\n",
    "import re\n",
    "import string\n",
    "def clean_text(text):\n",
    "    new=re.sub(\"<.*?>\",'',text)\n",
    "    final=''.join([word for word in new if word.lower() not in string.punctuation])\n",
    "    clean_text=' '.join([word for word in word_tokenize(final) if word.lower() not in stopwords.words('english')])       \n",
    "    \n",
    "    return clean_text\n",
    " \n",
    "# Apply cleaning function to the 'review' column\n",
    "data['clean_review'] = data['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fcce162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120b8aa-280d-4601-b4bc-07c8599236b5",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Model Building\n",
    "+ Prepare the data and labels; store them in `X` & `y` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5591f6e7-2eac-4f69-8727-4dac81691ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare data and labels\n",
    "X = data['clean_review']\n",
    "y = data['sentiment']\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ed7a3e-fb87-4c29-93e9-b07dd5f87cff",
   "metadata": {},
   "source": [
    "**Run the below cell to save your answer. Do not delete the cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63b617f3-3292-497c-867d-da3d273a38d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1 Passed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_imdb.save_ans1(data, clean_text, X, y)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3082ddd",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Task 2\n",
    "\n",
    "+ Create an instance of TF-IDF Vectorization with max features set to 5000 in variable `tfidf_vectorizer`.\n",
    "+ Fit and transform the data extracted and store it in `X_tfidf`.\n",
    "+ Split the dataset into training and testing named X_train, X_test, y_train, y_test with the newly transformed data and the labels with a test size of 20% and random state set to 42.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f94d5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X=tfidf_vectorizer.fit_transform(X)\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c5fa44-2f2e-45e4-a3f0-66c536b862fc",
   "metadata": {},
   "source": [
    "**Run the below cell to save your answer. Do not delete the cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "560fc046-0b4b-4494-868d-20962242914f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 2 Passed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_imdb.save_ans2(tfidf_vectorizer, X_train, X_test, y_train, y_test)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdbe266-6eef-4b60-a068-6c5a9a786f7a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Task 3\n",
    "\n",
    "+ Initialize SVM classifier with seed value of `42` stored in variable `svm`.\n",
    "+ Fit the training data to the classifier and gather the predictions against the testing data and store it in `y_pred`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ecc47a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize SVM classifier\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train,y_train) \n",
    "# Train the classifier\n",
    " \n",
    "# Predictions\n",
    "y_pred = svm.predict(X_test)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a682c006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f6838-9c51-4f24-a8d9-d33bedca5164",
   "metadata": {},
   "source": [
    "**Run the below cell to save your answer. Do not delete the cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f458f86-d75a-404c-8a2f-5c4744500d40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer has been saved\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_imdb.save_ans3(svm, y_pred)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8415fb1-c3ca-4297-9ae0-a96b150f307d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Task 5\n",
    "\n",
    "+ Evaluate the score for predictions against the testing data and store the output in `accuracy`.\n",
    "+ Get the classification report and of the predictions and the testing data as a dictionary and store it in `report`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "769ca9f6-5f0f-48b3-9fe5-f05267057982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8375\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    " \n",
    "# Classification report\n",
    "report = classification_report(y_test,y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f10db-0871-4197-b33c-5d44a92d33bc",
   "metadata": {},
   "source": [
    "**Run the below cell to save your answer. Do not delete the cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dd1bab7-996a-4d9c-a2f5-60ab495f085c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer has been saved\n"
     ]
    }
   ],
   "source": [
    "    try:\n",
    "        test_imdb.save_ans4(accuracy, report)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2bccf",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Task 6 : Word Frequency Analysis , Average Word Length Calculation\n",
    "+ Get the most common Top 10 words from the cleaned review data and store it as a dictionary.\n",
    "+ Name the dictionary as `wc_dict`. Example: {word1: count1, word2: count2}\n",
    "+ Use tokenization and counting methods to calculate word frequencies.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a50b1c9-10a8-48e2-9583-d13a4e612145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       One reviewers mentioned watching 1 Oz episode ...\n",
       "1       wonderful little production filming technique ...\n",
       "2       thought wonderful way spend time hot summer we...\n",
       "3       Basically theres family little boy Jake thinks...\n",
       "4       Petter Matteis Love Time Money visually stunni...\n",
       "                              ...                        \n",
       "1995    Feeling Minnesota directed Steven Baigelmann s...\n",
       "1996    CELL 2000 Rating 810The Cell like Antz must wa...\n",
       "1997    movie despite list B C list celebs complete wa...\n",
       "1998    loved movie could break tears watching really ...\n",
       "1999    worst movie ever seen Billy Zane understand mo...\n",
       "Name: clean_review, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e12dcae4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': 3158,\n",
       " 'film': 2750,\n",
       " 'one': 1704,\n",
       " 'like': 1397,\n",
       " 'good': 1031,\n",
       " 'would': 956,\n",
       " 'see': 897,\n",
       " 'even': 879,\n",
       " 'really': 840,\n",
       " 'story': 818}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze word frequency in the IMDb dataset\n",
    "# Display the top 10 most common words\n",
    "total=''.join(data['clean_review'])\n",
    "lister=total.split()\n",
    "word_counter=Counter(lister)\n",
    "wc_dict = {}\n",
    "top10=word_counter.most_common(10)\n",
    "for word,count in top10:\n",
    "    wc_dict.update({word:count})\n",
    "wc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cadac18a-e58b-4ea5-84ac-88a5428c1a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': 3158,\n",
       " 'film': 2750,\n",
       " 'one': 1704,\n",
       " 'like': 1397,\n",
       " 'good': 1031,\n",
       " 'would': 956,\n",
       " 'see': 897,\n",
       " 'even': 879,\n",
       " 'really': 840,\n",
       " 'story': 818}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newer=''.join(data['clean_review'])\n",
    "import nltk\n",
    "freq=nltk.FreqDist(word_tokenize(newer))\n",
    "f=freq.most_common(10)\n",
    "wc_dict=dict(f)\n",
    "wc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98805e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "ict = {'movie': 3321,\n",
    "    'film': 2851,\n",
    "    'one': 1762,\n",
    "    'like': 1433,\n",
    "    'good': 1051,\n",
    "    'would': 965,\n",
    "    'see': 919,\n",
    "    'even': 879,\n",
    "    'really': 857,\n",
    "    'story': 840}\n",
    "if sorted(wc_dict)==sorted(ict):\n",
    "    print('true')\n",
    "else:\n",
    "    print('false')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd0fc8",
   "metadata": {},
   "source": [
    "\n",
    "## Average Word Length Calculation\n",
    "- Compute the average word length in characters across the text dataset and store the result in `avg_word_length`.\n",
    "- Tokenize the text and calculate the average length of tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74435c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate average word length\n",
    "old=''.join(data['clean_review'])\n",
    "full=old.split()\n",
    "total_length=sum([len(word) for word in full])\n",
    "full_len=len(full)\n",
    "avg_word_length = total_length/full_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f3489ad-d4e3-4767-bb5b-dee585ab2934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.044327550669873"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_word_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae1e2c-8739-4e78-83ee-a5730fe99fe3",
   "metadata": {},
   "source": [
    "**Run the below cell to save your answer. Do not delete the cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fa8bf8a-ea16-45e8-b7b0-8b155c09e07e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer has been saved\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_imdb.save_ans5(wc_dict, avg_word_length)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d5a069-a018-44d2-8e81-15a21ae7f4cd",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39c80b",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> ! Note : After you finish solving the problem, please run the below cell to save your answers for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6b10dde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1 Failed\n",
      "Test Case 2 Passed\n",
      "Your answer has been saved\n",
      "Your answer has been saved\n",
      "Your answer has been saved\n"
     ]
    }
   ],
   "source": [
    "### Do not modify this block\n",
    "from test_imdb import test_imdb\n",
    "try:\n",
    "    test_imdb.save_answer(data, clean_text,X, y, tfidf_vectorizer,X_train, X_test, y_train, y_test,svm, y_pred, accuracy, report, wc_dict, avg_word_length)\n",
    "except:\n",
    "    print(\"Assign the answers to all the variables properly\")\n",
    "    test_imdb.remove_pickle()\n",
    "    try:\n",
    "        test_imdb.save_ans1(data, clean_text, X, y)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        test_imdb.save_ans2(tfidf_vectorizer, X_train, X_test, y_train, y_test)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        test_imdb.save_ans3(svm, y_pred)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        test_imdb.save_ans4(accuracy, report)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        test_imdb.save_ans5(wc_dict, avg_word_length)\n",
    "    except:\n",
    "        pass\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa424c8-f6e0-40f5-855d-839934dc11aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
